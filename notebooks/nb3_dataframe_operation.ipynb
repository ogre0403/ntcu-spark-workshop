{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global Path  \n",
    "Path=\"file:/home/spark/spark-workshop/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解壓縮測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! unzip /home/spark/spark-workshop/data.zip -d /home/spark/spark-workshop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RawUserRDD= sc.textFile(Path+\"data/u.user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RawUserRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RawUserRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userRDD =RawUserRDD.map(lambda line: line.split(\"|\"))\n",
    "userRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由RDD產生："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row \n",
    "userDF1 = userRDD.map(lambda u: Row(userid=u[0], age=int(u[1]), gender=u[2], occupation=u[3], zipcode=u[4]))\n",
    "schemaUser = spark.createDataFrame(userDF1)\n",
    "schemaUser.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由讀入csv檔產生："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userDF = spark.read.option(\"delimiter\",\"|\").option(\"inferSchema\",\"true\").csv(Path+\"data/u.user\")\n",
    "userDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df = userDF.toDF(\n",
    "    'userid', 'age', 'gender', 'occupation','zipcode')\n",
    "user_df.show(5)\n",
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=user_df.alias(\"df\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL tempTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.registerTempTable(\"user_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\" SELECT count(*) counts FROM user_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlDF = spark.sql(\" SELECT count(*) counts FROM user_table\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\" SELECT *  FROM user_table \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\" SELECT *  FROM user_table\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.sql(\" SELECT *  FROM user_table LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 顯示部分欄位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userRDDnew= userRDD.map(lambda x: (x[0],x[3],x[2] ,x[1]) )\n",
    "userRDDnew.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.select(\"userid\",\"occupation\",\"gender\",\"age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.select( user_df.userid, user_df.occupation,user_df.gender,user_df.age ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df[user_df['userid'],user_df['occupation'],user_df['gender'],user_df['age']  ].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL tempTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\" SELECT userid,occupation,gender,age  FROM user_table\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 篩選資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userRDD.filter(lambda r:   r[3]=='technician' and r[2]=='M' and r[1]=='24').take(6)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.filter(\"occupation='technician' \").filter(\"gender='M' \").filter(\"age=24\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.filter(\"occupation='technician' and gender='M' and age=24\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.filter((df.occupation=='technician' ) & (df.gender=='M' ) & (df.age==24)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.filter((df['occupation']=='technician' ) & (df['gender']=='M' ) & (df['age']==24)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spark SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\n",
    "'''SELECT *  \n",
    "FROM user_table \n",
    "where occupation='technician' and   gender='M' and age=24''').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#userRDD.sortBy(lambda x: int(x[1])).collect()\n",
    "userRDD.sortBy(lambda x: int(x[1]), ascending=False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "SELECT userid,occupation,gender,age   \n",
    "FROM user_table \n",
    "ORDER BY age\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "SELECT userid,occupation,gender,age   \n",
    "FROM user_table \n",
    "ORDER BY age DESC\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.select(\"userid\",\"occupation\",\"gender\",\"age\").orderBy(\"age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.select(\"userid\",\"occupation\",\"gender\",\"age\").orderBy(\"age\",ascending=0 ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.select(\"userid\",\"occupation\",\"gender\",\"age\").orderBy(df.age).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.select(\"userid\",\"occupation\",\"gender\",\"age\").orderBy(df.age.desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 群組統計資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD\n",
    "\n",
    "使用map/reduce概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userRDD.map(lambda x: (x[2],1)) \\\n",
    "               .reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userRDD.map(lambda x: ((x[2],x[3]),1)).reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "SELECT gender ,count(*)  counts  \n",
    "FROM   user_table \n",
    "GROUP BY gender\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "SELECT gender,occupation,count(*) counts  \n",
    "FROM   user_table \n",
    "GROUP BY gender,occupation \n",
    "\"\"\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.select(\"gender\")      \\\n",
    "            .groupby(\"gender\")  \\\n",
    "            .count().show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_df.select(\"gender\",\"occupation\").                 \\\n",
    "                groupby(\"gender\",\"occupation\").           \\\n",
    "                count().                                                   \\\n",
    "                orderBy(\"gender\",\"occupation\").           \\\n",
    "                show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipcodeDF = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(Path+\"data/free-zipcode-database-Primary.csv\")\n",
    "zipcode_df = zipcodeDF.select(\"Zipcode\",\"ZipCodeType\",\"City\",\"State\")\n",
    "zipcode_df.show(5)\n",
    "zipcode_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df=user_df.join(zipcode_df ,  \\\n",
    "    user_df.zipcode == zipcode_df.Zipcode, \"left_outer\")\n",
    "\n",
    "joined_df.printSchema()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.filter(\"state='NY' \").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GroupByState_df=joined_df.groupBy(\"state\").count()\n",
    "GroupByState_df.show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipcode_df.registerTempTable(\"zipcode_table\")\n",
    "zipcode_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "SELECT z.* \n",
    "FROM zipcode_table z \n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "SELECT u.* ,z.city,z.state \n",
    "FROM user_table u \n",
    "LEFT JOIN zipcode_table z  ON u.zipcode = z.zipcode\n",
    "WHERE z.state='NY'\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "SELECT z.state ,count(*)\n",
    "FROM user_table u\n",
    "LEFT JOIN zipcode_table z  ON u.zipcode = z.zipcode\n",
    "GROUP BY z.state \n",
    "\"\"\").show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 以Pandas DataFrame繪圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "GroupByState_pandas_df =GroupByState_df.toPandas().set_index('state')\n",
    "GroupByState_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GroupByState_pandas_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = GroupByState_pandas_df ['count']  \\\n",
    "            .plot(kind='bar', title =\"State \",figsize=(12,6),legend=True, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Occupation_df=sqlContext.sql(\"\"\" \n",
    "SELECT u.occupation ,count(*) counts\n",
    "FROM user_table u\n",
    "GROUP BY occupation\n",
    "\"\"\")\n",
    "Occupation_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Occupation_pandas_df =Occupation_df.toPandas().set_index('occupation')\n",
    "Occupation_pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax =Occupation_pandas_df['counts'].plot(kind='pie',\n",
    "           title =\"occupation\",figsize=(8,8),startangle=90,autopct='%1.1f%%')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab3: Apache Log Analysis\n",
    "Ref: [Web Server Log Analysis with Apache Spark](http://datascience-enthusiast.com/Python/DataFrame_apache_log.html)\n",
    "\n",
    "分別使用RDD、dataframe、spark sql分析下列三種情況：\n",
    "1. 算出status為304共有幾筆\n",
    "2. 在status為304的log裡，找出不同path的count\n",
    "3. 在status為304的log裡，找出不同host的count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[Lab3-1: Spark SQL](../labs/Lab3-1-SQL.ipynb)\n",
    "\n",
    "[Lab3-2: DataFrame](../labs/Lab3-2-DataFrame.ipynb)\n",
    "\n",
    "[Lab3-3: RDD](../labs/Lab3-3-RDD.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
